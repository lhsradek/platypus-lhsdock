# https://www.elastic.co/guide/en/logstash/current/plugins-inputs-beats.html
input {
  elastic_agent {
    port => 5044
    ssl => true
    ssl_certificate_authorities => ["${ELASTIC_SSL_CERTIFICATEAUTHORITY}"]
    ssl_certificate => "/usr/share/logstash/config/certs/logstash.crt"
    ssl_key => "/usr/share/logstash/config/certs/logstash.key"
    ssl_verify_mode => "force_peer"
  }
}

# for filebeat is [service][type] for elastic-agent is [data_stream][dataset]
filter {
  if [data_stream][dataset] == "traefik.access" {
    json { source => "message" }
    date {
      match => ["time", "ISO8601"]
      timezone => "UTC"
      target => "time"
    }
    if [@timestamp] !~ /.+/ {
      mutate { add_field => { "@timestamp" => "%{time}" } }
    }
    ruby { code =>'event.set("time", Time.at(event.get("time").to_f).strftime("%Y-%m-%d %H:%M"))' }
    if [RouterName] =~ /.+/ {
      mutate { replace => { "message" => "%{[app][id]} %{time} [%{DownstreamStatus}] %{ClientHost} - %{RouterName}: %{RequestMethod} %{RequestPath}" }
      }
    } else {
      mutate { replace => { "message" => "%{[app][id]} %{time} [%{DownstreamStatus}] %{ClientHost} - %{RequestAddr}: %{RequestMethod} %{RequestPath}" }
      }
    }
    mutate { remove_field => ["time"] }
    if [event][dataset] !~ /.+/ {
      mutate { add_field => { "[event][dataset]" => "traefik.access" } }
    }
  } else if [data_stream][dataset] =~ /nginx/ {
    mutate { replace => { "message" => "%{[app][id]} %{[message]}" } }
# for traefik.error
  } else if [log][file][path] =~ /traefik/ {
    kv { remove_char_value => "\"" }
    date {
      match => ["time", "ISO8601"]
      timezone => "UTC"
      target => "time"
    }
    ruby { code =>'event.set("time", Time.at(event.get("time").to_f).strftime("%Y-%m-%d %H:%M"))' }
    mutate { gsub => [ "msg", "\\n", " " ] }
    mutate { uppercase => [ "level" ] }
    mutate { replace => { "message" => "%{[app][id]} %{time} [%{level}] %{msg}" } }
    mutate { lowercase => [ "level" ] }
    mutate {
      add_field => {
        "[event][kind]" => "event"
        "[event][category]" => "log"
      }
      remove_field => ["time", "msg"]
    }
    if [event][dataset] !~ /.+/ {
      mutate { add_field => { "[event][dataset]" => "traefik.error" } }
    }
# elastic-agent in nginx policy have kibana as generic log
  } else if [log][file][path] =~ /kibana.log/ {
# https://github.com/elastic/logstash/blob/v1.4.0/patterns/grok-patterns    
    grok { match => { "message" => "^%{TIMESTAMP_ISO8601:time} \[%{LOGLEVEL:level}%{SPACE}\]\[%{DATA:logger}\] %{GREEDYDATA:msg}$" } }
# remove milisec. for ruby from time
    date {
      match => ["time", "ISO8601"]
      timezone => "UTC"
      target => "time"
    }
    ruby { code =>'event.set("time", Time.at(event.get("time").to_f).strftime("%Y-%m-%d %H:%M"))' }
    mutate { replace => { "message" => "%{[app][id]} %{time} [%{level}][%{logger}] %{msg}" } }
    mutate {
      lowercase => [ "level" ]
      remove_field => ["time", "msg"]
    }
    mutate {
      add_field => {
        "[event][kind]" => "event"
        "[event][category]" => "log"
      }
    }
    if [event][dataset] !~ /.+/ {
      mutate { add_field => { "[event][dataset]" => "kibana.log" } }
    }
  }
}

# https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html
output {
  elasticsearch {
    hosts => ["https://es01.${APP_HOST}.${APP_NET}:9200"]
    data_stream => true
    ssl => true
    cacert => ["${ELASTIC_SSL_CERTIFICATEAUTHORITY}"]
    user => "${LOGSTASH_USERNAME}"
    password => "${LOGSTASH_PASSWORD}"
  }
}
